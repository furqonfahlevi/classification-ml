{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import heapq\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"kendaraan_clean_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Tertarik\"])\n",
    "y = data[[\"Tertarik\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227225, 14) (56807, 14) (227225, 1) (56807, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDNode:\n",
    "    def __init__(self, points, y, left = None, right = None, distance = np.inf):\n",
    "        self.points = points\n",
    "        self.y = y\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.distance = distance\n",
    "    def __lt__(self, other):\n",
    "        return self.distance < other.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDTree:\n",
    "    def __init__(self, k = 2):\n",
    "        self.tree = None\n",
    "        self.k = k\n",
    "        self.depth = 0\n",
    "        self.heap = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        \n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "\n",
    "        self.tree = self._construct_tree(np.array(X), np.array(y).reshape(-1), 0)\n",
    "    \n",
    "    def _construct_tree(self, points, y, depth):\n",
    "        if len(points) == 0:\n",
    "            return None\n",
    "        \n",
    "        k = len(points[0])\n",
    "        axis = depth % k\n",
    "        \n",
    "        sort_by_axis = np.argsort(points[:, axis])\n",
    "        sorted_points = points[sort_by_axis]\n",
    "        sorted_y =  y[sort_by_axis]\n",
    "        mid = len(sorted_points) // 2\n",
    "\n",
    "        return KDNode(\n",
    "            sorted_points[mid],\n",
    "            sorted_y[mid],\n",
    "            self._construct_tree(sorted_points[:mid], sorted_y[:mid], depth + 1),\n",
    "            self._construct_tree(sorted_points[mid + 1:],sorted_y[mid + 1:], depth + 1)\n",
    "        )\n",
    "    \n",
    "    def _height(self, root):\n",
    "        if root is None:\n",
    "            return 0\n",
    "        return max(self._height(root.left), self._height(root.right)) + 1\n",
    "\n",
    "    def _isBalanced(self, root):\n",
    "        if root is None:\n",
    "            return True\n",
    "        \n",
    "        left_height = self._height(root.left)\n",
    "        right_height = self._height(root.right)\n",
    "\n",
    "        return abs(left_height - right_height) <= 1 and (self._isBalanced(root.left) and self._isBalanced(root.right) is True)\n",
    "\n",
    "    def isBalanced(self):\n",
    "        return self._isBalanced(self.tree)\n",
    "\n",
    "    def height(self):\n",
    "        return self._height(self.tree)\n",
    "\n",
    "    def nearest_neighbour_search(self, query_point):\n",
    "        k = len(query_point)\n",
    "        heapq.heapify(self.heap)\n",
    "\n",
    "        def search(tree, depth):\n",
    "            if tree is None:\n",
    "                return\n",
    "\n",
    "            axis = depth % k\n",
    "            diff = query_point[axis] - tree.points[axis]\n",
    "            \n",
    "            if diff <= 0:\n",
    "                close, away = tree.left, tree.right\n",
    "            else:\n",
    "                close, away = tree.right, tree.left\n",
    "\n",
    "            \n",
    "            # d = euclidean(tree.points, query_point)\n",
    "            d = np.linalg.norm(query_point - tree.points)\n",
    "            tree.distance = -d\n",
    "            \n",
    "            search(close, depth + 1)\n",
    "\n",
    "            if len(self.heap) < self.k:\n",
    "                heapq.heappush(self.heap, tree)\n",
    "            else:\n",
    "                if heapq.nsmallest(1, self.heap)[0].distance < -d:\n",
    "                    heapq.heapreplace(self.heap, tree)\n",
    "\n",
    "            if len(self.heap) < self.k or abs(heapq.nsmallest(1, self.heap)[0].distance) > abs(d):\n",
    "                search(away, depth + 1)\n",
    "\n",
    "        search(self.tree, 0)\n",
    "        nds = heapq.nsmallest(self.k, self.heap)\n",
    "        return nds\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        results = []\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X_test = X_test.values\n",
    "            \n",
    "        for test in X_test:\n",
    "            result = self.nearest_neighbour_search(test)\n",
    "            predict_values = [x.y for x in result]\n",
    "            results.append(statistics.mode(predict_values))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdtree = KDTree(k = 5)\n",
    "kdtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = kdtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with K-NN: 86.73%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93     56056\n",
      "           1       0.01      0.13      0.03       751\n",
      "\n",
      "    accuracy                           0.87     56807\n",
      "   macro avg       0.50      0.51      0.48     56807\n",
      "weighted avg       0.97      0.87      0.92     56807\n",
      "\n",
      "[[49165  6891]\n",
      " [  650   101]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "precision = accuracy_score(y_pred, y_test) * 100\n",
    "class_report = classification_report(y_pred, y_test)\n",
    "print(\"Accuracy with K-NN: {0:.2f}%\".format(precision))\n",
    "print(class_report)\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\milha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, algorithm='kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_1 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with K-NN: 84.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91     52204\n",
      "           1       0.21      0.31      0.25      4603\n",
      "\n",
      "    accuracy                           0.85     56807\n",
      "   macro avg       0.57      0.60      0.58     56807\n",
      "weighted avg       0.88      0.85      0.86     56807\n",
      "\n",
      "[[46659  5545]\n",
      " [ 3156  1447]]\n"
     ]
    }
   ],
   "source": [
    "precision1 = accuracy_score(y_pred_1, y_test) * 100\n",
    "class_report = classification_report(y_pred_1, y_test)\n",
    "print(\"Accuracy with K-NN: {0:.2f}%\".format(precision1))\n",
    "print(class_report)\n",
    "print(confusion_matrix(y_pred_1, y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ef2aa9c3263e35572280c43a636090afbda352cb7456d858433bc6d0518c73c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
